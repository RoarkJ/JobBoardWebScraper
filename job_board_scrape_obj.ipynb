{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8600870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from splinter import Browser\n",
    "import time\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from cryptography.fernet import Fernet\n",
    "from config import user, passw\n",
    "from secure.run_encrypter import get_key\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74597872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to database.\n",
    "class Database:\n",
    "    def __init__(self, db_addr):\n",
    "        self.db_addr = db_addr\n",
    "\n",
    "    def connect(self):\n",
    "        self.conn=self.db_addr\n",
    "        self.client=pymongo.MongoClient(self.conn)\n",
    "        try:\n",
    "            print(f\"Connection to MongoDB Version {self.client.server_info()['version']} successful.\")\n",
    "        except Exception:\n",
    "            print(\"Unable to connect to the server.\")\n",
    "        # Create/Connect to Database and Collection\n",
    "        return self.client.Job_Boards.job_listings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94a865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, site_name, url, driver=\"chrome\"):\n",
    "        self.site_name = site_name\n",
    "        self.url = url\n",
    "        self.driver = driver\n",
    "        self.browser = Browser(self.driver)\n",
    "        self.browser.visit(self.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6b0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebLogin(Website):\n",
    "    # Some desired data may require login while other data is available without login.\n",
    "    # and to facilitate polymorphic design---\n",
    "    # I choose to not have login within the parent Website class\n",
    "    # and not have web navigation intially go to login page/section/window.\n",
    "    \n",
    "    # In the event the website landing page does not directly have login.\n",
    "    @property\n",
    "    def login_selector(self):\n",
    "        pass\n",
    "    \n",
    "    def login(self):\n",
    "        self.browser.find_by_id('username').fill(user)\n",
    "        self.browser.find_by_id('password').fill(str(Fernet(get_key()).decrypt(passw), 'UTF-8'))\n",
    "        self.browser.find_by_tag('button').click()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d359022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class JobData:\n",
    "    job_board_name: str\n",
    "    job_title: str\n",
    "    company_name: str\n",
    "    job_description: str\n",
    "    \n",
    "    def render(self):\n",
    "        return {\"job_board_name\": self.job_board_name, \"job_title\": self.job_title, \"company_name\": self.company_name, \"job_description\": self.job_description}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd7581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector:\n",
    "    def __init__(self, browser, jobs_board_name, db, search_term):\n",
    "        self.browser = browser\n",
    "        self.jobs_board_name = jobs_board_name\n",
    "        self.db = db\n",
    "        self.pn = 1\n",
    "        self.job_nav = 1\n",
    "        self.search_term = search_term\n",
    "        \n",
    "    def nav_to_data_page(self):\n",
    "        self.browser.visit('{website_landing_page}')\n",
    "        # Reasons you might want or need to navigate differently:\n",
    "        # If you are trying to look more like a human.\n",
    "        # Sometimes websites href is a reference to the page as opposed to the actual url extension\n",
    "        # and the url, upon loading, may show uniquely generated reference as opposed to the hard url.\n",
    "        # Also, sometimes this reference is uniquely generated each time the page loads.\n",
    "        # Additionally, not following the path a website sets user on potentially causes,\n",
    "        # depending upon scraper navigation implementation, Cross Site Request Forgery(CSRF) blocking.\n",
    "        \n",
    "        # Here is an example of how one might deal in script with these scenarios \n",
    "        # and avoid unnecessary website research:\n",
    "            # data_page = self.browser.html\n",
    "            # time.sleep(1)\n",
    "            # job_page_link = (re.search(r'href=\"/jobsrefpattern/\" id=\"idpattern', data_page)).group()\n",
    "            # job_page_link_id=job_page_link.split('\"')\n",
    "            # job_page_link_id = job_page_link_id[3]\n",
    "            # self.browser.find_by_id(job_page_link_id).click()\n",
    "            \n",
    "    def query_data(self):\n",
    "        jobs_search_cont = self.browser.find_by_css(\"{search_field_container}\")\n",
    "        jobs_search_cont = jobs_search_cont.html\n",
    "        time.sleep(1)\n",
    "        job_keyword_search_field = (re.search(r\"element_id_regex\", jobs_search_cont)).group()\n",
    "        self.browser.find_by_id(job_keyword_search_field).fill(self.search_term)\n",
    "        time.sleep(1)\n",
    "        self.browser.find_by_text('text_string').click()\n",
    "        \n",
    "    # Why not just make nav_data_pgs_obj an attribute of the class or simply a variable? \n",
    "    # Without giving a detailed exampled explanation:\n",
    "    # The attributes of this object can change (depending on website implementation) \n",
    "    # as we navigate through the pages.\n",
    "    @property\n",
    "    def nav_data_pgs_obj(self):\n",
    "        return self.browser.find_by_tag('element_tag')[int].find_by_tag('ul')[int]\n",
    "\n",
    "    def traverse_data(self):\n",
    "        while self.pn <= int(self.nav_data_pgs_obj.find_by_tag('li')[-1].text):\n",
    "            print(f'pn number is now: {self.pn}')\n",
    "            print(\"RUNNING PAGE JOB DESCRIPTION NAVIGATION\")\n",
    "            # Create splinter WebDriverElement object of ul element containing jobs.\n",
    "            jobs_list_obj = self.browser.find_by_tag('element_tag')[2].find_by_tag('ul')[int]\n",
    "            print(\"Ran part One\")\n",
    "            time.sleep(3)\n",
    "            # Create string of html for regex search for job ids.\n",
    "            jobs_list_obj_html_string = jobs_list_obj.html\n",
    "            print(\"Ran part Two\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Divine list of Jobs li element ids.\n",
    "            jobs_ids_list_not_cleaned = re.findall('<element_id_regex', jobs_list_obj_html_string)\n",
    "            print(len(jobs_ids_list_not_cleaned))\n",
    "            print(\"Ran part Three\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            #Create and fill list with cleaned job ids.\n",
    "            job_ids = [job.split('\"')[1] for job in jobs_ids_list_not_cleaned]\n",
    "            \n",
    "            # Navigate through jobs list for current page.\n",
    "            self.job_nav = 1        \n",
    "            for job_id in job_ids:\n",
    "                self.job_post = jobs_list_obj.find_by_id(job_id)\n",
    "                # Breakup click pattern with if else.\n",
    "                if self.job_nav %2 == 0:\n",
    "                    self.job_post.find_by_tag('element_tag')[int].mouse_over()\n",
    "                    self.job_post.find_by_tag('element_tag')[int].click()\n",
    "                    time.sleep(2)\n",
    "                    self.etl_data()\n",
    "                    \n",
    "                else:\n",
    "                    self.job_post.find_by_tag('element_tag')[int].mouse_over()\n",
    "                    self.job_post.find_by_tag('element_tag')[int].click()\n",
    "                    time.sleep(2)\n",
    "                    self.etl_data()\n",
    "            self.nav_data_pages()\n",
    "                    \n",
    "    def etl_data(self):\n",
    "        # EXTRACT JOB DATA:(May be a good idea to split etl to separate methods to enhance polymorphism.)\n",
    "        print(f\"Job number: {self.job_nav} selected.\")\n",
    "        # Assign the company name for currently selected job posting to a variable\n",
    "        company_name = self.job_post.find_by_tag(\"element_tag\")[int].text\n",
    "        print(company_name)\n",
    "        # Create splinter ElementList of all elements that make up single job complete description.\n",
    "        description_inner_span = self.browser.find_by_xpath('element_xpath')\n",
    "        # Assign the company name for currently selected job posting to a variable\n",
    "        # Query HTML(returns as string) from ElementList Object of complete job description.\n",
    "        desc_html_span = description_inner_span.html\n",
    "\n",
    "        # TRANSFORM JOB DATA:\n",
    "        # Using Regex replace all element tags in job description HTML-string with a space.(Transform/Clean Data)\n",
    "        desc_html_span = desc_html_span.replace('\\n', \"\").replace('<br>\\n', \"\").replace('<br>', \" \").replace('&nbsp;', \"\").replace('/', \" \").replace('&amp;', \" \")\n",
    "        job_description = re.sub(\"(<.+?>)+\", \" \", desc_html_span)\n",
    "        print(job_description)\n",
    "        print(\"Ran part Five\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # print(JobData(self.jobs_board_name, self.search_term, company_name, job_description).render())\n",
    "        # LOAD JOB DATA:\n",
    "        db.insert_one(JobData(self.jobs_board_name, self.search_term, company_name, job_description).render())\n",
    "        self.job_nav += 1\n",
    "        \n",
    "    def nav_data_pages(self):\n",
    "        # Breakup the patter with if elif else.\n",
    "        if self.job_nav % 2 == 0:\n",
    "            time.sleep(3)\n",
    "        elif self.job_nav % 3 == 0:\n",
    "            time.sleep(4)\n",
    "        elif self.job_nav % 7 == 0:\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "        self.pn += 1\n",
    "        lis = self.nav_data_pgs_obj.find_by_tag('element_tag')\n",
    "        # Account for page navigation button with alternate navigation attributes.\n",
    "        if self.pn == 9:\n",
    "            lis[8].click()\n",
    "            time.sleep(3)\n",
    "        # Account for typical page navigation button navigation attibutes.\n",
    "        elif self.pn != (int(lis[-1].text)+1):\n",
    "            for li in lis:\n",
    "                if li.text == str(self.pn):\n",
    "                    li.click()\n",
    "                    time.sleep(3)\n",
    "                    break\n",
    "        # Message declaring jobs navigation completion. WooHoo!!!\n",
    "        else:\n",
    "            print(f\"You have reached the end of job postings for {self.search_term}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a8c6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MongoDB Version 5.0.3 successful.\n"
     ]
    }
   ],
   "source": [
    "db = Database(\"mongodb://localhost:27017\").connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80b5344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x10b8efa40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db.insert_one({\"test_key\": \"test_value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf75dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = WebLogin('{name_of_job_board}', '{url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad444a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "site.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922fd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = DataCollector(site.browser, site.site_name, db, \"Chocolatier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b5020a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.nav_to_data_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84e416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.query_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde2d447",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jobs.traverse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7c9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
